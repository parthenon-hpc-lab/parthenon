# =========================================================================================
# Parthenon performance portable AMR framework
# Copyright(C) 2020-2024 The Parthenon collaboration
# Licensed under the 3-clause BSD License, see LICENSE file for details
# =========================================================================================
# (C) (or copyright) 2020-2024. Triad National Security, LLC. All rights reserved.
#
# This program was produced under U.S. Government contract 89233218CNA000001 for Los
# Alamos National Laboratory (LANL), which is operated by Triad National Security, LLC
# for the U.S. Department of Energy/National Nuclear Security Administration. All rights
# in the program are reserved by Triad National Security, LLC, and the U.S. Department
# of Energy/National Nuclear Security Administration. The Government is granted for
# itself and others acting on its behalf a nonexclusive, paid-up, irrevocable worldwide
# license in this material to reproduce, prepare derivative works, distribute copies to
# the public, perform publicly and display publicly, and to permit others to do so.
# =========================================================================================

from __future__ import print_function
import h5py as h
import os, sys, errno
import numpy as np


class Swarm:
    """A Python object representing swarm data. Generated by the phdf class.
    Class Attributes:
          name: The name of the swarm
          variables: The variables in available in the swarm.
          varData: The swarm variables. Greedily accessed.
          x, y, z: The x, y, and z positions of the swarm
    """

    def __init__(self, fid, swarmname):
        self.fid = fid
        self.gid = fid[f"/{swarmname}/SwarmVars"]
        self.name = swarmname
        self.variables = list(self.gid.keys())
        self.varData = {}
        self.offsets = fid[f"/{swarmname}/offsets"][:]
        self.counts = fid[f"/{swarmname}/counts"][:]

    def Block(self, b):
        """Returns a Python slice for the particles only on block b"""
        return slice(self.offsets[b], self.offsets[b] + self.counts[b] + 1)

    def Get(self, variable):
        """Reads data for the named swarm var from file and caches it in the
        dictionary. Returns None if variable is not found in the file
        or data. Data is always of shape:
        [tensor indices, particle index]
        """
        try:
            if self.varData.get(variable) is None:
                self.varData[variable] = self.gid[variable][:]
            return self.varData[variable]
        except KeyError:
            print(f"ERROR: {variable} not found in {self.name}")
            return None

    @property
    def x(self):
        return self.Get("swarm.x")

    @property
    def y(self):
        return self.Get("swarm.y")

    @property
    def z(self):
        return self.Get("swarm.z")

    def __getitem__(self, key):
        return self.Get(key)


class phdf:
    """A reader for the new HDF5 output.  Reads in a hdf5 file which
    is the only argument to the constructor.

    Class Attributes:
            Filename: Name of file that was read
                Time: Simulation time
              NCycle: Simulation cycle
             NumDims: Number of dimensions in problem run
            MaxLevel: Max level in grid
           NumBlocks: Total number of blocks
       MeshBlockSize: Size of each mesh block
       CellsPerBlock: Number of cells in each block
          TotalCells: Total number of cells in simulation
           Variables: List of variables that were written to file
                   x: Flat array of X coordinates of x cell centers
                   y: Flat array of Y coordinates of y cell centers
                   z: Flat array of Z coordinates of z cell centers

    Additional attributes for a block:
       isGhost[CellsPerBlock]: Array of size CellsPerBlock indicating ghost cells
      BlockIdx[CellsPerBlock]: Converts a cell index to [iz, iy, ix] that are
                               indices within the block for data access
       BlockBounds[NumBlocks]: Bounds of all the blocks

    Class Functions:
      Get(variable, flatten=True, interior=False, average_to_cell_centers=True):
           Reads data for the named variable from file.

           Returns None if variable is not found in the file or the data
           if found.

           Default is to return a flat array of length
           TotalCells*total tensor components. However if flatten is
           set to False, a 4D (or 5D, or 6D if tensorial) array is
           returned that has dimensions
           [NumBlocks, tensor_components, Nz, Ny, Nx]
           where NumBlocks is the total number of blocks, and Nz, Ny,
           and Nx are the number of cells in the z, y, and x
           directions respectively.

           If flatten is False and interior is True, only non-ghost data
           will be returned. This array will correspond to the coordinates
           xg and xng, etc.

           By default, node, face, and edge centered variables are
           averaged to cell centers for visualization. This can be
           disabled by setting average_to_cell_centers = False.
      ToLocation(index):
           Returns the location as an array [ib, bidx, iz, iy, ix]
           which convets the index into a block, index within that
           block, and z, y, and x locations within that block

      findIndexInOther(self,otherFile,idx,tol=1e-10):
        Given an index in my data, find the index in a different file.
        Cell centers have to match within tol.
        I've curently implemented a naive algorithm and will improve
        later

    """

    def __init__(self, filename):
        """
        Initializes a python structure with the information from
        the provided file.

        filename = name of parthenon hdf5 file
        """
        self.err = 0
        self.file = filename
        try:
            f = h.File(filename, "r")
        except:
            raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), filename)

        # Read in the timestep attributes
        info = f["Info"]
        self.fid = f
        self.NumDims = info.attrs["NumDims"]
        try:
            self.NCycle = info.attrs["NCycle"]
        except:
            self.NCycle = -1
        try:
            self.Time = info.attrs["Time"]
        except:
            self.Time = 0.0
        try:
            self.NGhost = info.attrs["NGhost"]
        except:
            self.NGhost = -1
        try:
            self.IncludesGhost = info.attrs["IncludesGhost"]
        except:
            self.IncludesGhost = 0
        self.NumBlocks = info.attrs["NumMeshBlocks"]
        self.MeshBlockSize = info.attrs["MeshBlockSize"]
        try:
            self.BlocksPerPE = info.attrs["BlocksPerPE"]
        except:
            self.BlocksPerPE = np.array((1), self.NumBlocks)
        try:
            self.OutputFormatVersion = info.attrs["OutputFormatVersion"]
        except:
            self.OutputFormatVersion = -1
        self.Coordinates = info.attrs["Coordinates"]
        self.CellsPerBlock = np.prod(self.MeshBlockSize)
        self.TotalCells = self.NumBlocks * self.CellsPerBlock

        # Read in Params (older output files don't have this, so make it optional)
        if "Params" in f:
            self.Params = dict(f["Params"].attrs)
        else:
            self.Params = None

        # Read in coordinates
        def load_coord(coord_i):
            coord_name = ["x", "y", "z"][coord_i]

            coordf = f["/Locations/" + coord_name][:, :]
            vol_loc = "/VolumeLocations/" + coord_name
            if vol_loc in f:
                coord = f[vol_loc][:, :]
            else:
                coord = np.zeros((self.NumBlocks, self.MeshBlockSize[coord_i]))
                for bId in range(self.NumBlocks):
                    for cId in range(self.MeshBlockSize[coord_i]):
                        coord[bId, cId] = 0.5 * (
                            coordf[bId, cId] + coordf[bId, cId + 1]
                        )
            return coord, coordf

        def load_ghost_coords(coord_i):
            """
            Here, ghost coordinates refers to coordinates that are offset from the physical coordinates
            to include ghost zones. All coordinates are defined on vertices.

            On completion:
            coordg - ghost coords corresponding to the variable arrays
            coordi - ghost coords of points on the interior of the block
                     (which equals coordg when the data is only given in the interior)
            coorde - ghost coords of the entire block
                     (which equals coordg when the data includes ghost data)
            coordi_ng - The non-ghost coordinates of the interior of the block
            """
            coord_name = ["x", "y", "z"][coord_i]
            logical_locations = np.array(f["/LogicalLocations"][:, coord_i])
            coordg = np.array(f["/Locations/" + coord_name][:, :])
            levels = np.array(f["/Levels"])

            if not self.IncludesGhost:
                coordi_ng = np.array(coordg)
            else:
                coordi_ng = np.array(coordg[:, self.NGhost : -self.NGhost])

            for iblock in range(coordg.shape[0]):
                dx = coordg[iblock, 1] - coordg[iblock, 0]
                coordg[iblock, :] += (
                    (logical_locations[iblock] * 2 + 1) * dx * self.NGhost
                )

            if self.IncludesGhost:
                coordi = coordg[:, self.NGhost : -self.NGhost]
                coorde = coordg

            else:
                coordi = coordg
                coorde = np.zeros((coordg.shape[0], coordg.shape[1] + 2 * self.NGhost))
                coorde[:, self.NGhost : -self.NGhost] = coordg
                dx_all = coordg[:, 1] - coordg[:, 0]
                for i in range(self.NGhost):
                    coorde[:, self.NGhost - 1 - i] = coorde[:, self.NGhost - i] - dx_all
                    coorde[:, -self.NGhost + i] = (
                        coorde[:, -self.NGhost - 1 + i] + dx_all
                    )

            return coordg, coordi, coorde, coordi_ng

        self.x, self.xf = load_coord(0)
        self.y, self.yf = load_coord(1)
        self.z, self.zf = load_coord(2)

        self.xg, self.xig, self.xeg, self.xng = load_ghost_coords(0)
        self.yg, self.yig, self.yeg, self.yng = load_ghost_coords(1)
        self.zg, self.zig, self.zeg, self.zng = load_ghost_coords(2)

        # fill in self.offset and block bounds
        self.offset = [0, 0, 0]
        for i in range(3):
            if self.MeshBlockSize[i] > 1:
                self.offset[i] = self.NGhost * self.IncludesGhost

        # Read in block ids and sparse info
        self.level = np.array(f["/Blocks/loc.level-gid-lid-cnghost-gflag"][:, 0])
        self.gid = np.array(f["/Blocks/loc.level-gid-lid-cnghost-gflag"][:, 1])

        # fill in self.BlockBounds
        self.BlockBounds = [None] * self.NumBlocks
        xo = self.NGhost * self.IncludesGhost
        iOffsets = [
            self.offset[0],
            self.MeshBlockSize[0] - self.offset[0],
            self.offset[1],
            self.MeshBlockSize[1] - self.offset[1],
            self.offset[2],
            self.MeshBlockSize[2] - self.offset[2],
        ]
        eps = 1e-8
        for ib in range(self.NumBlocks):
            self.BlockBounds[ib] = [
                self.xf[ib, iOffsets[0]] - eps,
                self.xf[ib, iOffsets[1]] + eps,
                self.yf[ib, iOffsets[2]] - eps,
                self.yf[ib, iOffsets[3]] + eps,
                self.zf[ib, iOffsets[4]] - eps,
                self.zf[ib, iOffsets[5]] + eps,
            ]
        # Save info
        self.Info = dict(f["/Info"].attrs)

        # generate self.offset, isGhost and BlockIdx arrays
        self.GenAuxData()

        self.TotalCellsReal = self.NumBlocks * np.prod(
            self.MeshBlockSize - 2 * self.offset
        )

        self.MaxLevel = info.attrs["MaxLevel"]

        self.Variables = [k for k in f.keys()]
        self.varData = {}
        self.varTopology = {}
        self.swarmData = {}

        # Construct a map of datasets to contained components,idx
        self.DatasetComponentsMap = {}
        # Construct a map of datasets to number contained components
        try:
            self.DatasetNumComponents = dict(
                zip(
                    np.array(info.attrs["OutputDatasetNames"]).ravel().astype(str),
                    np.array(info.attrs["NumComponents"]).ravel(),
                )
            )
        except:
            self.DatasetNumComponents = {}
        # Construct a map of components to parent datasets,idx
        self.ComponentsDatasetMap = {}
        idx_i = 0
        for dataset, num_components in self.DatasetNumComponents.items():
            num_components = num_components.astype(int)

            component_names = (
                np.array(info.attrs["ComponentNames"])
                .ravel()
                .astype(str)[idx_i : idx_i + num_components]
            )
            component_indices = list(range(num_components))

            self.DatasetComponentsMap[dataset] = dict(
                zip(component_names, component_indices)
            )

            # Note: if a component is in multiple datasets, then this map
            # will point to the last dataset that contains it
            self.ComponentsDatasetMap.update(
                {
                    name: (dataset, idx)
                    for name, idx in zip(component_names, component_indices)
                }
            )

            idx_i += num_components

    def GenAuxData(self):
        """
        Additional attributes filled in by function GenAuxData():
                          offset[3]: Offsets for real cells in the block
             isGhost[CellsPerBlock]: Array of size CellsPerBlock indicating ghost cells
            BlockIdx[CellsPerBlock]: Converts a cell index to [ib, bidx, iz, iy, ix]
                                     into [ a block ID, index within that
                                     block, and z, y, and x locations within that block]
             BlockBounds[NumBlocks]: Bounds of all the blocks
        """
        # flag for ghost cells.
        # Logic is easier starting with all ghost and unmarking
        self.offset = np.zeros(3, "i")
        for i in range(3):
            if self.MeshBlockSize[i] > 1:
                self.offset[i] = self.NGhost * self.IncludesGhost
        xRange = range(self.MeshBlockSize[0])
        yRange = range(self.MeshBlockSize[1])
        zRange = range(self.MeshBlockSize[2])
        xo = [self.offset[0], self.MeshBlockSize[0] - self.offset[0]]
        yo = [self.offset[1], self.MeshBlockSize[1] - self.offset[1]]
        zo = [self.offset[2], self.MeshBlockSize[2] - self.offset[2]]

        self.BlockIdx = np.reshape(
            np.array(np.meshgrid(zRange, yRange, xRange)).transpose(2, 1, 3, 0),
            (self.MeshBlockSize[0] * self.MeshBlockSize[1] * self.MeshBlockSize[2], 3),
        )
        self.isGhost = (
            (zo[0] > self.BlockIdx[:, 0])
            | (self.BlockIdx[:, 0] >= zo[1])
            | (yo[0] > self.BlockIdx[:, 1])
            | (self.BlockIdx[:, 1] >= yo[1])
            | (xo[0] > self.BlockIdx[:, 2])
            | (self.BlockIdx[:, 2] >= xo[1])
        )

    def ToLocation(self, index):
        """
        Converts an index to [blockID, bidx, Z, Y, X]
        """

        ib = int(index / self.CellsPerBlock)
        bidx = index % self.CellsPerBlock
        [iz, iy, ix] = self.BlockIdx[bidx]
        return [ib, bidx, iz, iy, ix]

    #    def isPointInBlock(self,
    def findIndexInOther(self, other, idx, tol=1e-10, verbose=0):
        """
        Given an index in my data, find the index in a different file.
        Cell centers have to match within tol.
        I've curently implemented a naive algorithm and will improve
        later
        """
        [ib, bidx, iz, iy, ix] = self.ToLocation(idx)

        (myX, myY, myZ) = (self.x[ib, ix], self.y[ib, iy], self.z[ib, iz])

        # now hunt in other file
        for ib1 in range(other.NumBlocks):
            ib1Bounds = other.BlockBounds[ib1]
            # compute deltas
            # see if block bounds match
            if myX < ib1Bounds[0] or myX > ib1Bounds[1]:
                continue
            if self.NumDims > 1 and (myY < ib1Bounds[2] or myY > ib1Bounds[3]):
                continue
            if self.NumDims > 2 and (myZ < ib1Bounds[4] or myZ > ib1Bounds[5]):
                continue

            # smart finder:
            deltas = [other.x[ib1][1] - other.x[ib1][0], 1.0, 1.0]
            if other.MeshBlockSize[1] > 1:
                deltas[1] = other.y[ib1][1] - other.y[ib1][0]
            if other.MeshBlockSize[2] > 1:
                deltas[2] = other.z[ib1][1] - other.z[ib1][0]

            ix1 = (
                int(round((myX - other.x[ib1][other.offset[0]]) / deltas[0]))
                + other.offset[0]
            )
            if self.NumDims > 1:
                iy1 = (
                    int(round((myY - other.y[ib1][other.offset[1]]) / deltas[1]))
                    + other.offset[1]
                )
            else:
                iy1 = 0

            if self.NumDims > 2:
                iz1 = (
                    int(round((myZ - other.z[ib1][other.offset[2]]) / deltas[2]))
                    + other.offset[2]
                )
            else:
                iz1 = 0

            otherX, otherY, otherZ = (
                other.x[ib1, ix1],
                other.y[ib1, iy1],
                other.z[ib1, iz1],
            )
            if (
                abs(myX - otherX) > tol
                or abs(myY - otherY) > tol
                or abs(myZ - otherZ) > tol
            ):
                print("skipping:", ib1, [ix1, iy1, iz1], [otherX, otherY, otherX])
                continue

            iCell1 = ix1 + other.MeshBlockSize[0] * (iy1 + iz1 * other.MeshBlockSize[1])
            idx1 = ib1 * other.CellsPerBlock + iCell1
            return [idx1, ib1, iCell1, iz1, iy1, ix1]

        if verbose:
            print("ox=")
            for xx in other.x:
                print("    ", ["%.20lf" % x for x in xx])

            print("oy=")
            for yy in other.y:
                print("    ", ["%.20lf" % y for y in yy])

            print("oz=")
            for zz in other.z:
                print("    ", ["%.20lf" % z for z in zz])

            print("deltas=", deltas)
            print("bounds:")
            for b in other.BlockBounds:
                print(b)
                print("me=", idx, self.isGhost[bidx], [ib, bidx, iz, iy, ix])
                print("LOOKING:", idx, ["%.20lf" % x for x in [myX, myY, myZ]])

        raise ValueError("Unable to map cell")

    def findBlockIdxInOther(self, other, ib, tol=1e-10, verbose=False):
        """
        Given an meshblock index in my data, find the meshblock index in a different file.
        """

        myibBounds = np.array(self.BlockBounds[ib])

        # now hunt in other file
        for ib1 in range(other.NumBlocks):
            ib1Bounds = np.array(other.BlockBounds[ib1])

            if np.all(np.abs(myibBounds - ib1Bounds) < tol):
                return ib1

        if verbose:
            print(f"Block id: {ib} with bounds {myibBounds} not found in {other.file}")
        return None  # block index not found

    def Get(self, variable, flatten=True, interior=False, average_to_cell_centers=True):
        """Reads data for the named variable from file.

        Returns None if variable is not found in the file or the data
        if found.

        Default is to return a flat array of length
        TotalCells*total tensor components. However if flatten is
        set to False, a 4D (or 5D, or 6D if tensorial) array is
        returned that has dimensions
        [NumBlocks, tensor_components, Nz, Ny, Nx]
        where NumBlocks is the total number of blocks, and Nz, Ny,
        and Nx are the number of cells in the z, y, and x
        directions respectively.

        If flatten is False and interior is True, only non-ghost data
        will be returned. This array will correspond to the coordinates
        xg and xng, etc.

        By default, node, face, and edge centered variables are
        averaged to cell centers for visualization. This can be
        disabled by setting average_to_cell_centers = False.
        """
        try:
            if self.varData.get(variable) is None:
                self.varData[variable] = self.fid[variable][:]
                vShape = self.varData[variable].shape
                if self.OutputFormatVersion < 3:
                    raise ValueError("Unsupported output version")

        except KeyError:
            print(
                """
            ERROR in phdf.Get: Unable to read %s from file %s
            """
                % (variable, self.file)
            )
            return None

        try:
            self.varTopology[variable] = (
                self.fid[variable].attrs["TopologicalLocation"].astype(str)
            )
        except:
            self.varTopology[variable] = "Cell"
        average_able = (self.varTopology[variable] != "Cell") and (
            self.varTopology[variable] != "None"
        )

        vShape = self.varData[variable].shape
        simdim = (vShape[-1] > 1) + (vShape[-2] > 1) + (vShape[-3] > 1)
        if average_to_cell_centers and average_able:
            v = self.varData[variable]
            vnew = v.copy()
            # Make vnew the proper shape to be averaged into
            vnew = vnew[..., :-1]
            if simdim >= 2:
                vnew = vnew[..., :-1, :]
            if simdim >= 3:
                vnew = vnew[..., :-1, :, :]

            # Average...
            if self.varTopology[variable] == "Face":
                if simdim == 1:
                    vnew[:, 0] = 0.5 * (v[:, 0, ..., 1:] + v[:, 0, ..., :-1])
                elif simdim == 2:
                    vnew[:, 0] = 0.5 * (v[:, 0, ..., :-1, 1:] + v[:, 0, ..., :-1, :-1])
                    vnew[:, 1] = 0.5 * (v[:, 1, ..., 1:, :-1] + v[:, 1, ..., :-1, :-1])
                else:  # simdim == 3
                    vnew[:, 0] = 0.5 * (
                        v[:, 0, ..., :-1, :-1, 1:] + v[:, 0, ..., :-1, :-1, :-1]
                    )
                    vnew[:, 1] = 0.5 * (
                        v[:, 1, ..., :-1, 1:, :-1] + v[:, 1, ..., :-1, :-1, :-1]
                    )
                    vnew[:, 2] = 0.5 * (
                        v[:, 2, ..., 1:, :-1, :-1] + v[:, 2, ..., :-1, :-1, :-1]
                    )
            if self.varTopology[variable] == "Edge":
                if simdim == 1:
                    # nothing to do for E1 == :,0
                    # E2 and E3 behave like node-centered data
                    vnew[:, 1] = 0.5 * (v[:, 1, ..., 1:] + v[:, 1, ..., :-1])
                    vnew[:, 2] = 0.5 * (v[:, 2, ..., 1:] + v[:, 2, ..., :-1])
                if simdim == 2:
                    # E1 and E2 behave like face centered data
                    vnew[:, 0] = 0.5 * (v[:, 0, ..., 1:, :-1] + v[:, 0, ..., :-1, :-1])
                    vnew[:, 1] = 0.5 * (v[:, 1, ..., :-1, 1:] + v[:, 1, ..., :-1, :-1])
                    # E3 behaves like node-centered data
                    vnew[:, 2] = 0.25 * (
                        v[:, 2, ..., 1:, 1:]
                        + v[:, 2, ..., 1:, :-1]
                        + v[:, 2, ..., :-1, 1:]
                        + v[:, 2, ..., :-1, :-1]
                    )
                else:  # simdim == 3
                    vnew[:, 0] = 0.25 * (
                        v[:, 0, ..., 1:, 1:, :-1]
                        + v[:, 0, ..., 1:, :-1, :-1]
                        + v[:, 0, ..., :-1, 1:, :-1]
                        + v[:, 0, ..., :-1, :-1, :-1]
                    )
                    vnew[:, 1] = 0.25 * (
                        v[:, 1, ..., 1:, :-1, 1:]
                        + v[:, 1, ..., 1:, :-1, :-1]
                        + v[:, 1, ..., :-1, :-1, 1:]
                        + v[:, 1, ..., :-1, :-1, :-1]
                    )
                    vnew[:, 2] = 0.25 * (
                        v[:, 2, ..., :-1, 1:, 1:]
                        + v[:, 2, ..., :-1, 1:, :-1]
                        + v[:, 2, ..., :-1, :-1, 1:]
                        + v[:, 2, ..., :-1, :-1, :-1]
                    )
            elif self.varTopology[variable] == "Node":
                if simdim == 1:
                    vnew = (1.0 / 2.0) * (v[..., 1:] + v[..., :-1])
                elif simdim == 2:
                    vnew = (1.0 / 4.0) * (
                        v[..., 1:, 1:]
                        + v[..., 1:, :-1]
                        + v[..., :-1, 1:]
                        + v[..., :-1, :-1]
                    )
                else:  # simdim == 3
                    vnew = (1.0 / 8.0) * (
                        v[..., 1:, 1:, 1:]
                        + v[..., :-1, :-1, :-1]
                        + v[..., 1:, 1:, :-1]
                        + v[..., 1:, :-1, 1:]
                        + v[..., :-1, 1:, 1:]
                        + v[..., :-1, :-1, 1:]
                        + v[..., :-1, 1:, :-1]
                        + v[..., 1:, :-1, :-1]
                    )
            else:
                raise ValueError(
                    "Topology {} for var {} cannot be averaged.".format(
                        self.varTopology[variable], variable
                    )
                )
            v = vnew
            self.varData[variable] = v

        if flatten:
            nblocks = vShape[0]
            if self.varTopology[variable] == "None":
                remaining_size = np.prod(vShape[1:])
                return self.varData[variable].reshape(nblocks, remaining_size)
            else:
                preserved_shape = vShape[:-3]
                remaining_size = np.prod(vShape[-3:])
                return self.varData[variable].reshape(*preserved_shape, remaining_size)

        if self.IncludesGhost and interior:
            nghost = self.NGhost
            if vShape[-1] == 1:
                return self.varData[variable][:]
            elif vShape[-2] == 1:
                return self.varData[variable][..., nghost:-nghost]
            elif vShape[-3] == 1:
                return self.varData[variable][..., nghost:-nghost, nghost:-nghost]
            else:
                return self.varData[variable][
                    ..., nghost:-nghost, nghost:-nghost, nghost:-nghost
                ]
        return self.varData[variable][:]

    def GetSwarm(self, swarm):
        """
        Gets a swarm object if it exists. If swarm not present, returns None.
        """
        try:
            if self.swarmData.get(swarm) is None:
                self.swarmData[swarm] = Swarm(self.fid, swarm)
            return self.swarmData[swarm]
        except KeyError:
            print(f"ERROR in GetSwarm: {swarm} not found in {self.file}")
            return None

    def GetComponents(self, components, flatten=True):
        """
        Reads data for the named components from file.

        Returns components as a dictionary of {component:component_data}

        Throws an exception if the components do not exist in the file

        Default is to return a flat array of length TotalCells.  However if
        flatten is set to False, a 4D for each component array is returned that
        has dimensions [NumBlocks, Nz, Ny, Nx] where NumBlocks is the total
        number of blocks, and Nz, Ny, and Nx are the number of cells in the z,
        y, and x directions respectively.

        Components can be from a single variable or spread across multiple variables.

        Components refer to top-level components of variables. The number of
        components and the names of each component in variables are specified in
        the phdf file in Info/NumComponents and Info/ComponentNames with
        variables in the order of Info/OutputDatasetNames.

        In the c++ code, components of variables can be named by supplying a
        std::vector of std::strings when creating the Metadata for variables.
        Without specifying component names, by default variables have a single
        component with the same name as the variable. See the Parthenon docs
        outputs.md#preparing-outputs-for-yt for details.
        """

        # Check if these components exist
        missing_components = [
            component
            for component in components
            if not component in self.ComponentsDatasetMap
        ]
        if len(missing_components) > 0:
            raise Exception(
                f"Components {missing_components} are missing from {self.file}"
            )

        # Determine which Datasets contain components
        dataset_names = set(
            self.ComponentsDatasetMap[component][0] for component in components
        )

        # Start a map of required components
        component_data = {}

        for dataset_name in dataset_names:
            dataset = self.Get(dataset_name, flatten=flatten)

            for component, idx in self.DatasetComponentsMap[dataset_name].items():
                if component in components:
                    if self.DatasetNumComponents[dataset_name] == 1:
                        # If dataset isn't a vector, just save dataset
                        component_data[component] = dataset
                    else:
                        if flatten:
                            component_data[component] = dataset[idx, ...]
                            # need to take leading block index into account
                        else:
                            component_data[component] = dataset[:, idx, ...]

        return component_data

    def __GenLocMeshGrid(self, z, y, x, flatten):
        """
        Returns Z[grid_idx,k,j,i], Y[grid_idx,k,j,i], X[grid_idx,k,j,i] full
        arrays of locations from 2D arrays z[grid_idx,k], y[grid_idx,j],
        x[grid_idx,i]
        """

        if not (x.shape[0] == y.shape[0] == z.shape[0]):
            raise Exception("z,y,x have different number of grids")

        # loc[grid_idx,k,j,i]
        loc_shape = (x.shape[0], z.shape[1], y.shape[1], x.shape[1])

        Z = np.empty(loc_shape)
        Y = np.empty(loc_shape)
        X = np.empty(loc_shape)

        for grid_idx in range(loc_shape[0]):
            Z[grid_idx], Y[grid_idx], X[grid_idx] = np.meshgrid(
                z[grid_idx], y[grid_idx], x[grid_idx], indexing="ij"
            )

        if flatten:
            Z = Z.ravel()
            Y = Y.ravel()
            X = X.ravel()

        return Z, Y, X

    def GetVolumeLocations(self, flatten=True):
        """
        Returns Z,Y,X arrays of volume centered locations in the dataset

        Default is to return a flat array of length TotalCells.  However if
        flatten is set to False, a 4D for each dimension is returned that has
        dimensions [NumBlocks, Nz, Ny, Nx] where NumBlocks is the total number
        of blocks, and Nz, Ny, and Nx are the number of cells in the z, y, and
        x directions respectively.
        """

        return self.__GenLocMeshGrid(self.z, self.y, self.x, flatten)

    def GetFaceLocations(self, flatten=True):
        """
        Returns Z,Y,X arrays of face centered locations in the dataset

        Default is to return a flat array of length TotalCells.  However if
        flatten is set to False, a 4D for each dimension is returned that has
        dimensions [NumBlocks, Nz, Ny, Nx] where NumBlocks is the total number
        of blocks, and Nz, Ny, and Nx are the number of cells in the z, y, and
        x directions respectively.
        """

        return self.__GenLocMeshGrid(self.zf, self.yf, self.xf, flatten)

    def __str__(self):
        return (
            """
-------------------------------------------
    Filename=%s
-------------------------------------------
                Time=%.4lf
              NCycle=%d
             NumDims=%d
            MaxLevel=%d
           NumBlocks=%d
       MeshBlockSize=%s
       CellsPerBlock=%d
          TotalCells=%d
      TotalCellsReal=%d
               NumPE=%d
         BlocksPerPE=%s
              NGhost=%d
       IncludesGhost=%d
         Coordinates=%s
 OutputFormatVersion=%d
--------------------------------------------
           Variables="""
            % (
                self.file,
                self.Time,
                self.NCycle,
                self.NumDims,
                self.MaxLevel,
                self.NumBlocks,
                self.MeshBlockSize,
                self.CellsPerBlock,
                self.TotalCells,
                self.TotalCellsReal,
                np.sum(self.BlocksPerPE.shape),
                self.BlocksPerPE,
                self.NGhost,
                self.IncludesGhost,
                self.Coordinates,
                self.OutputFormatVersion,
            )
            + str([k for k in self.Variables])
            + """
--------------------------------------------
"""
        )


if __name__ == "__main__":
    files = sys.argv[1:]
    for filename in files:
        ba = phdf(filename)
        print(ba)
        l = ba.Get("c.c.bulk.momentum")
        print("cmom=", l.shape)
        l = ba.Get("c.c.bulk.bulk_modulus")
        print("mod=", l.shape)
        print(help(ba))
